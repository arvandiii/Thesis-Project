{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: emoji in /home/alireza/.local/lib/python3.10/site-packages (2.7.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in /home/alireza/.local/lib/python3.10/site-packages (4.32.0)\n",
      "Requirement already satisfied: filelock in /home/alireza/.local/lib/python3.10/site-packages (from transformers) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /home/alireza/.local/lib/python3.10/site-packages (from transformers) (0.16.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/alireza/.local/lib/python3.10/site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/alireza/.local/lib/python3.10/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/lib/python3/dist-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/alireza/.local/lib/python3.10/site-packages (from transformers) (2023.6.3)\n",
      "Requirement already satisfied: requests in /usr/lib/python3/dist-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/alireza/.local/lib/python3.10/site-packages (from transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/alireza/.local/lib/python3.10/site-packages (from transformers) (0.3.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/alireza/.local/lib/python3.10/site-packages (from transformers) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /home/alireza/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/alireza/.local/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.5.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /home/alireza/.local/lib/python3.10/site-packages (2.0.1)\n",
      "Requirement already satisfied: filelock in /home/alireza/.local/lib/python3.10/site-packages (from torch) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /home/alireza/.local/lib/python3.10/site-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /home/alireza/.local/lib/python3.10/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /home/alireza/.local/lib/python3.10/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/alireza/.local/lib/python3.10/site-packages (from torch) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (59.6.0)\n",
      "Requirement already satisfied: wheel in /usr/lib/python3/dist-packages (from nvidia-cublas-cu11==11.10.3.66->torch) (0.37.1)\n",
      "Requirement already satisfied: cmake in /home/alireza/.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (3.27.2)\n",
      "Requirement already satisfied: lit in /home/alireza/.local/lib/python3.10/site-packages (from triton==2.0.0->torch) (16.0.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/alireza/.local/lib/python3.10/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/alireza/.local/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n",
      "\u001b[33mDEPRECATION: distro-info 1.1build1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of distro-info or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mDEPRECATION: python-debian 0.1.43ubuntu1 has a non-standard version number. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of python-debian or contact the author to suggest that they release a version with a conforming version number. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip3 install emoji\n",
    "!pip3 install transformers\n",
    "!pip3 install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/paramiko/transport.py:236: CryptographyDeprecationWarning: Blowfish has been deprecated\n",
      "  \"class\": algorithms.Blowfish,\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import emoji\n",
    "import re\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def clean_text(text):\n",
    "    if not isinstance(text, str): return \"\"\n",
    "    text = text.lower()\n",
    "    text = emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "    text = re.sub(r'http\\S+|www\\S+', ' LINK ', text)\n",
    "    text = re.sub(r'@\\S+', ' MENTION ', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file_name = 'reddit_clean.csv'\n",
    "ouput_file_name = 'reddit_labeled.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reddit_data = pd.read_csv(input_file_name)\n",
    "\n",
    "selected_columns = ['id', 'title', 'selftext', 'subreddit', 'permalink']\n",
    "selected_data = reddit_data[selected_columns].copy()\n",
    "selected_data['label'] = 0\n",
    "\n",
    "sampled_data = selected_data.sample(n=50)\n",
    "\n",
    "sampled_data.to_csv(ouput_file_name, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>permalink</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14eo63g</td>\n",
       "      <td>williams lake fire department to practice hazm...</td>\n",
       "      <td></td>\n",
       "      <td>WilliamsLakeNews</td>\n",
       "      <td>https://www.reddit.com/r/WilliamsLakeNews/comm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>132ppze</td>\n",
       "      <td>update: wildfire burning in the chilcotin west...</td>\n",
       "      <td></td>\n",
       "      <td>WilliamsLakeNews</td>\n",
       "      <td>https://www.reddit.com/r/WilliamsLakeNews/comm...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>137u4hk</td>\n",
       "      <td>parks canada prescribed burn in banff becomes ...</td>\n",
       "      <td></td>\n",
       "      <td>canada</td>\n",
       "      <td>https://www.reddit.com/r/canada/comments/137u4...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15bndew</td>\n",
       "      <td>big building fire in east van</td>\n",
       "      <td>looks like it's somewhere near guelph park. ho...</td>\n",
       "      <td>vancouver</td>\n",
       "      <td>https://www.reddit.com/r/vancouver/comments/15...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15hbe5d</td>\n",
       "      <td>vancouver police investigate stanley park fire...</td>\n",
       "      <td></td>\n",
       "      <td>vancouver</td>\n",
       "      <td>https://www.reddit.com/r/vancouver/comments/15...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                              title  \\\n",
       "0  14eo63g  williams lake fire department to practice hazm...   \n",
       "1  132ppze  update: wildfire burning in the chilcotin west...   \n",
       "2  137u4hk  parks canada prescribed burn in banff becomes ...   \n",
       "3  15bndew                      big building fire in east van   \n",
       "4  15hbe5d  vancouver police investigate stanley park fire...   \n",
       "\n",
       "                                            selftext         subreddit  \\\n",
       "0                                                     WilliamsLakeNews   \n",
       "1                                                     WilliamsLakeNews   \n",
       "2                                                               canada   \n",
       "3  looks like it's somewhere near guelph park. ho...         vancouver   \n",
       "4                                                            vancouver   \n",
       "\n",
       "                                           permalink  label  \n",
       "0  https://www.reddit.com/r/WilliamsLakeNews/comm...      0  \n",
       "1  https://www.reddit.com/r/WilliamsLakeNews/comm...      0  \n",
       "2  https://www.reddit.com/r/canada/comments/137u4...      0  \n",
       "3  https://www.reddit.com/r/vancouver/comments/15...      0  \n",
       "4  https://www.reddit.com/r/vancouver/comments/15...      0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labeled_data = pd.read_csv(ouput_file_name)\n",
    "labeled_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alireza/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "labeled_data_0 = pd.read_csv('reddit_labeled_0.csv')\n",
    "labeled_data_1 = pd.read_csv('reddit_labeled_1.csv')\n",
    "labeled_data = pd.concat([labeled_data_0, labeled_data_1])\n",
    "unlabeled_data = pd.read_csv('reddit_clean.csv')\n",
    "unlabeled_data['label'] = 0\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_length):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        title = self.data.iloc[idx]['title']\n",
    "        selftext = self.data.iloc[idx]['selftext']\n",
    "        text = title if isinstance(title, str) else ''  + ' ' + selftext if isinstance(selftext, str) else ''\n",
    "        label = self.data.iloc[idx]['label']\n",
    "        \n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,\n",
    "            truncation=True,\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'label': label\n",
    "        }\n",
    "\n",
    "seed_dataset = labeled_data.sample(n=min(len(labeled_data), 50))\n",
    "train_dataset = CustomDataset(seed_dataset, tokenizer, max_length=512)\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "model.train()\n",
    "for batch in train_loader:\n",
    "    optimizer.zero_grad()\n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    labels = batch['label']\n",
    "    outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "    loss = outputs.loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "unlabeled_dataset = CustomDataset(unlabeled_data, tokenizer, max_length=512)\n",
    "unlabeled_loader = DataLoader(unlabeled_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model.eval()\n",
    "uncertainty_scores = []\n",
    "for batch in unlabeled_loader:\n",
    "    input_ids = batch['input_ids']\n",
    "    attention_mask = batch['attention_mask']\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask=attention_mask).logits\n",
    "    probs = softmax(logits, dim=1)\n",
    "    uncertainty = torch.max(probs, dim=1).values\n",
    "    uncertainty_scores.extend(uncertainty.cpu().numpy())\n",
    "\n",
    "uncertainty_scores = torch.tensor(uncertainty_scores)\n",
    "selected_indices = uncertainty_scores.argsort(descending=True)[:50]\n",
    "selected_indices = selected_indices[selected_indices < len(unlabeled_data)]\n",
    "selected_examples = unlabeled_data.iloc[selected_indices]\n",
    "\n",
    "selected_examples.to_csv('next.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
